\# ğŸ“Š Analytics Copilot â€” RAG â†’ SQL â†’ Insight



An end-to-end \*\*LLM-powered Analytics Copilot\*\* that translates natural language business questions into \*\*validated SQL queries\*\*, executes them on a DuckDB warehouse, and returns \*\*charts and insights\*\* via Streamlit.



This project demonstrates how Retrieval-Augmented Generation (RAG) can be safely applied to analytics workflows without hallucinating metrics or queries.



---



\## ğŸš€ Key Features



\- ğŸ” \*\*Semantic KPI Retrieval (RAG)\*\* using ChromaDB

\- ğŸ§  \*\*LLM-powered SQL generation\*\* with fallback safety

\- ğŸ›‘ \*\*Guardrails\*\*: refuses unsupported or low-confidence questions

\- ğŸ—„ï¸ \*\*DuckDB analytics warehouse\*\* (Olist dataset)

\- ğŸ“ˆ \*\*Interactive Streamlit dashboard\*\* (charts + tables)

\- ğŸ§ª \*\*Evaluation harness\*\* with pass/fail scoring



---



\## ğŸ—ï¸ Architecture





---



\## ğŸ§° Tech Stack



\- Python

\- DuckDB

\- ChromaDB

\- OpenAI API

\- Streamlit

\- Pandas

\- YAML (KPI definitions)



---



\## ğŸ“Œ Example Questions



âœ”ï¸ Supported:

\- Show revenue by month  

\- Top products by revenue  

\- What is average order value?  

\- Number of orders  



âŒ Refused (by design):

\- What is net promoter score?  

\- How many suppliers do we have?  



---



\## ğŸ”’ Safety \& Reliability



\- Retrieval confidence gating (prevents wrong KPIs)

\- Explicit grain validation (prevents invalid aggregations)

\- SQL fallback examples when LLM cannot answer

\- No hallucinated metrics



---



\## â–¶ï¸ Run Locally



```bash

python -m venv .venv

.venv\\Scripts\\activate

pip install -r requirements.txt

python -m streamlit run app/streamlit\_app.py



